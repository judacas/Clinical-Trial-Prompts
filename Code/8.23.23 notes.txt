Use the logit_bias in order to bias it towards better jsons and also could possibly bias it towards picking words it has already chosen before.

I am essentially using Solo performance prompting (SPP) which just means that I am using multiple personas to complete the task. Right now it is always the same task and always in the same order so I have the system messages and function order predetermined and everything. HOWEVER, for more variable tasks it could eventually come up with those prompts and personas itself and call those functions itself. Chatgpt does have the functionality to say it needs to call a function. Could make a higher up AI which just decides which high level functions to call, each high level function could then have some other AI which determines which lower level function to call and so on. Essentially having the decision making with AI and then you outline what the AI can do. can build better chatbot by having the orignial prompt just decide which chatbot should answer it. then have specialized chatbots for each which have specialized prompts and parameters. could even maybe have AI dynamically change that prompt and those parameters to improve it.

could make a chatbot which makes this type of chatbot. Where the initial prompt just has as input the possible topics or questions it can get asked. determine which personas it must make, make each persona, and improve each persona. 

more likely to be able to only work for turning unstructured data into structured data

Ran into rate limit problems. Was because would continue to try when the error was just too many tokens instead of switching to 16k

somehow got an endless loop of ands where the llm would simply output indented ands over and over again. honestly don't know why.