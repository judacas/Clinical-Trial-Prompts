GPT3.5 is quite bad at maintaining a specific role and staying in it. its steerabilty is quite low. 
GPT4 can be steered much better. I wonder if it will work even better once I get the API and can use System Messages. 

MatchMiner github: https://github.com/dfci/matchminer 
MatchMiner Documentation: https://matchminer.gitbook.io/matchminer/
OncoTree: http://oncotree.mskcc.org/#/home




Summary of work: 
CTT 8 in chatgpt to obtain information
gpt 3.5 not steerable enough. needed to do research to make gpt 4 more steerable. have not tested the new prompt with gpt 3.5 but no need since this does not look a forseeable path. 
after some research I developed a prompt which makes sure that the user doesn't get off task and that chatgpt4 will persists untill it gets the information it needs in a kind and compassionate way which doesn't give up. after some iterations it now provides the last bit of output in a way parseable to use in an api. 

Then I read up on matchminer. Found that it uses yaml or json and since I'd never worked with either I read up and researched what they really are and the differences. 

Researched ctml and tried to understand its format. found that matchminer uses too much molecular/genomic data for what we want. we want a patient who doesn't need to go to the clinic. yet matchminer requires genomic data from the get go which is impossible to acquires

I however did not realize this at first and tried researching how we could get some of the data. looked at onco tree and tried to see if chatgpt could get the oncotree_primary_diagnosis_name. could not. gpt does not know all of the specific leaves of the oncotree. tried to look into using the oncotree api to get all the leaves and give chatgpt its options. deemed it feasible, but did not follow through because I realized that the others are not as easy, and even then a patient might not know what specific tumor they have all the way down to the leaf.

think best way is for gpt to do the matchmaking but we get around the token limit using some more fancy tricks I researched. saving things into files. we take the proccess we talked about before were we just figure out what information we need from each trial. we save them into a file. we go one by one and save them into some type of dictionary. anytime that something repeats, instead of adding a new entry we just add one to the value of that key. that then gives us which things most clinical trials need. we go asking questions. and also using that tree diagram. the matchmaking can be done algorithmically but the information grabbing through gpt. 

talk about gpt cache. there are going to be lots of repeated things and so gpt cache can save lots of money.


ask for gpt api how that's going


for next week define what we want to work on and what the different compononets are. what can we 

decision trees